# Deep Learning
项目名称介绍及作用
Application_Checkpoint.py
	神经网络的检查点  :  应用程序检查点
      是长时间运行进行的容错技术,  是在系统故障的情况下,   对系统状态快照保存的一种方法
      当训练深度学习的模型时 :
         可以利用检查点来捕获模型的权重,可以基于当前的权重进行预测,也可以使检查点保存的权重值继续训练模型
      ModeCheckpoint 回调类 可以定义模型权重值检查点的位置, 文件的名称,以及在什么情况下创建模型的检查点
      其中保存的文件, 也是通过  HDF5 格式文件来保存
	  
BankMarketing.py
	通常与同一个客户会进行多次通话沟通,客户明确购买或不买的情况下会被记录到这个数据集中,基于现有的数据集统计,分析客户是否会购买新的产品
		数据集 : bank.csv   葡萄牙银行机构电话营销活动的记录

						
Complex_CNN.py
						发现问题 : 默认是tf  所以数据维度千万不要错了
					    图片维序类型为 th 时（dim_ordering='th'）： 输入数据格式为[samples][channels][rows][cols]；
					    图片维序类型为 tf 时（dim_ordering='tf'）： 输入数据格式为[samples][rows][cols][channels]；
					复杂卷积神经网络
					网络拓扑结构 : 
					    卷积层 : 30个特征图,感受野大小 5x5
					    采样因子 : pool_size 为 2x2 的池化层
					    卷积层,具有15个特征图,感受野大小为 3x3
					    采样因子 : pool_size 为 2x2的池化层
					    Dropout概论Wie20% 的Dropout层
					    Flatten层
					    具有128个神经元和ReLU激活函数的全连接层
					    具有50个神经元和ReLU激活函数的全连接层
					    输出层
					'''
housing.py  
	 房价预测
			输入维度相同数量的神经元的单层完全全连接的隐藏层,13个神经元,				隐藏层才有 ReLU 激活函数
			由于是回归问题,不要对预测结果进行分类,所以输出层不用设置激活函数
			
ImageRecognition.py 
	简单卷积神经网络 CNN  简单的图像识别
	
ImageRecognition1.py'	
	大型卷积神经网络 CNN  图像处理识别
	
ImageRecognition2.py
	改进模型 -  大型卷积神经网络  ,图像处理模型
	
IMDB_Analysis.py
	'''
情感分析实例 : 
     IMDB影评情感分析
     数据集 :
        包含25000部电影的评价信息
        Keras 提供的数据集将单词转化成整数 , 代表单词在整个数据集中的流行程度
	'''

IMDB_Analysis1.py
	'''
#词嵌入 - 将单词的正整数表示转换为词嵌入,需要指定词汇大小预期的最大数量,以及输出的每个词向量的维度
    多层感知器模型
	'''


IMDB_Analysis2.py
	卷积神经网络 :  分析情感分析模型
	
Improving_Iamge.py
	Keras 中的图片增强API
    通过ImageDataGenerator类来实现增强处理功能 ：
        1.特征标准化
        2.ZCA白化
        3.随机旋转，移动，剪切和反转图像
        4.维度排序
        5.保存增强后的图像
		数据集 ： 采用 Keras 中 mnist
		
IrisSortFlower.py
	莺尾花分类模型
创建一个简单的全连接网络
    包括一个输入层(4个神经元) 两个隐藏层 一个输出层(3个神经元,多分类问题的输出层通常具有与分类类别相同的神经元个数,这里包括3个神经元)
    第一个隐藏层,4个神经元,与输入层的神经元一致,使用ReLU激活函数
    第二个隐藏层,6个神经元,同样使用 ReLU激活函数 


JSON_Serialization.py
	JSON 序列化模型构建
	
Keras_Dropout.py
	输入层 Dropout
    是神经网络提出的一个 正则化方法 ， 其中正则化强度代表着函数的光滑程序，光滑代表连续， 联系代表可导
    原理 ： 在训练的过程中，随机的忽略部分的神经元 ， 通过 rate = 0.2  ， 每个周期更新随机忽略20% 的训练数据
    效果 ： 减弱了神经元节点间的联合适应性， 增强了泛化能力


LearningRate.py
	学习率衰减 : 
     选择合适的学习率 , 能够提高 随机梯度算法的性能 ,并减少训练时间
     学习率决定参数移动到最优值的速度,如果学习率过大,可能会越过最优值,反之,优化的效率可能过低,长时间算法无法收敛
     
     两种学习率衰减方法 : 线性衰退(根据epoch逐步降低学习率)
                        指数衰退(在特渡部分的epoch使用分数快速降低学习率)
						

Loop_RNNs.py
			循环神经网络   RNNs   -  主要用于处理  序列化数据的神经网络
			 应用于 :  价格走势预测 , 自然语言处理  等
			    传统的神经网络模型中 : 层与层之间是全连接的,每层的节点之间是无连接的  ,处理序列问题低效
			    处理序列数据的神经网络成为  循环神经网络
			        是因为一个序列当前的输出与前面的输出有关
			            网络会对前面的信息进行记忆,并应用于当前输出的计算中 , 隐藏层之间的节点不再是无连接的,而是有连接的,并且隐藏层的输入不仅包括输入层的输出,还包括上一时刻隐藏层的输出
			    循环神经网络能够对任何长度的序列数据进行处理 ,具有 循环连接,随着时间的推移向网络增加反馈和记忆
			    这种记忆能力增强了循环神经网络对序列化问题的网络学习和泛化输出能力

			长短期记忆网络(LSTM) 的循环神经网络 ,对处理自然语言翻译到各种各样图像和视屏自动字幕等序列问题
			    基于LSTM 的系统被应用广泛
			        列如 : 自然语言翻译  控制机器人  图像分析  文档摘要  语音识别  图像识别  手写识别  聊天机器人  预测疾病   点击率  股票   合成音乐 等

			    序列问题分类 :
			        一对多  : 序列输出, 用于图像字幕
			        多对一  : 序列输入, 用于情感分类
			        多对多  : 序列输入和输出 ,用于机器翻译
					
					
Model_Incremental_Updating.py
		模型增量更新
    为了保证模型的时效性, 需要定期的进行更新, 通常时间间隔为 3- 6 个月
    数据量非常大的时候, 若每次采用全部数据去重新训练模型, 则时间开销非常大
    因此 . 采用增量更新模型的方式,对模型进行训练

		对于时间序的预测,增量更新相当于 默认给最新的数据增加了权重, 模型的准确度相对会比较好
		实际过程中,采用增量更新模型, 需要做的与 全面更新的对比实验 , 以确保 增量恒信的可行性


Number_Recognition.py
	数字图片识别   
    预测结果:  是途中的手写数字识别0~9


pima-indians-diabetes.py
pima-indians-diabetes1.py
pima-indians-diabetes2.py
	 多层感知器 
    印第安人糖尿病诊断
    数据集 : pima-indians-diabetes.csv
    创建神经网络模型的步骤 :
    1.导入数据
    2.定义模型
    3.编译模型
    4.训练模型
    5.评估模型
    6.汇总代码
	

Simple_CNN.py	
	简单的卷积神经网络
	网络拓扑结构  :
    输入层 : 1x28x28个输入
    卷积层 : 32maps 5x5
    池化层 : 2x2
    Dropout层 : 20%
    Flatten层 
    全连接层 : 128
    输出层 : 10个神经元

Visualization_training_process.py
	模型训练过程的可视化


YAML_Serialization.py
	是 JSON 的另外一个 标记语言 ,强调的是以  数据为中心, 而不是以标签为重点
是一种 能够被电脑 识别的直观的数据序列格式	
